%=========================================================================
% (c) Ivan Ševčík, 2015
abb:
EEG,
PC,
CPU,
GPU,
API,
SDK,
DWT,
DFT,
FFT,

%TODO: articles and commas check, check, check..
%TODO: http://www.grammarbook.com/punctuation/commas.asp
%TODO: conjuctive adverb
\chapter{Introduction}
%TODO: citations in this chapter too
% Uvod do temy
The brain is central organ of human nervous system and as such has very
important role in almost every activity. However, its complexity makes it
difficult to study and understand. Rapid development of computers in recent
decades provided partial solution to this as it allowed for mapping and
monitoring both structure and activity of brain with high precision,
undoubtedly resulting in great increase in the rate of new discoveries. For
example, ..
%TODO: priklady

% Aktualny stav, problemy
But raising interest in EEG technology and brain-computer interfaces also means
that there is an evident need for user interfaces and applications capable of
processing these signals for various purposes. One such purpose is visualization
that allows researchers and users to better comprehend measured data as these
are usually just binary values that may be represented as integer or decimal
numbers, therefore hard for humans to interpret. Another issue is that,
generally, users are not interested in raw values but in some features that
signal carries such as intensity at certain frequency or specific patterns that
represent certain activity performed by measured subject.

% Ciele
The goal of this work is to create an application implementing several
methods for signal processing and visualization, including classification by
frequency, charts showing wavelet of measured signal in time domain, and both
two and three-dimensional models displaying brain acitivity. Another important
task will be to create intuitive and clean, yet highly customizable graphical
user interface, which will be responsive also for real-time signal inputs. The
application should, however, be able to process also large offline data measured
earlier without noticeable performance decrease.

% O com to tu je
The text is structured into chapters that start as a general theory and
progressively get more specific, concluded by an application concept and
implementation. In chapter \ref{humanBrain}, background information about brain
and methods for measuring its activity, specifically EEG, is presented. Moving
on, chapter \ref{appProcVis} provides required foundations of signal processing
and computer visualization. Chapter \ref{eegProcAndSol} puts these general
methods into context of EEG analysis and also contains reviews of few existing
solutions in field that serve as an inspiration for this work. The concept is
introduced in chapter \ref{concept} and eventually transforms into
implementation, which is described in chapter \ref{implementation}.
 
\chapter{Human brain} \label{humanBrain}
Brain is a central unit of human nervous system and has important role in almost
every aspect of life. It performs both conscious tasks and automatic operation
of vital organs, like breathing, maintaining blood pressure and releasing
hormones. It also processes all sensory inputs, such as odors, sounds or light,
interprets them and make associations with representations preserved in memory.
\section{Brain biology}
The biology of brain is complex and many processes that are ongoing within it
are still not well understood. In this section we will, therefore, provide only
very brief introduction to its anatomy and communication mechanisms that are
relevant for this work.
\subsection{Anatomy}
From anatomy point of view, we are interested in cerebrum, which is the
outermost structure of brain. It is divided into two separate hemispheres
bridged by bundle of fibers. The cerebrum is associated with higher-order
functioning and the control of voluntary behavior. This include thinking,
perceiving, planning and understanding language. The cerebrum is covered with a
sheet of tissue called cerebral cortex, which is further divided into regions
that are functionally differentiated and called lobes. There are four lobes,
each with different role. The frontal lobe is where initiation and coordination
of motor movements take place, along with higher cognitive skills, such as
thinking, planning and organizing. It is also important for personality and
emotional makeup. The parietal lobe is responsible for processing sensory
inputs, attention, language and spatial orientation. The occipital lobe helps
process visual information and assists with recognition of shapes and colors.
Finally, the temporal lobe is region where auditory information is processed and
the information from other senses is integrated. It also has a role in
short-term memory and in learned emotional responses. \cite{brainFacts} The
image bellow shows all discussed structures on the model of brain.
%TODO: obrazok, render, popisky

\subsection{Neurons}
The nervous tissue is made of cells called neurons that communicate with each
other and represent basic working units of brain. The neuron consists of cell
body, dendrites and an axon. The cell body contains nucleus and cytoplasm, and
produces peptides required for communication. Dendrites extend from cell and
receive signals from other neurons through synapses -- contact points where
axons of other neurons connects to dendrite. The axon is used to transmit
electrical impulses outward from neuron. These electrical impulses originate
from sudden change of electrical potential caused by flow of ions through cell
membrane. The change, called an action potential, then passes along axon's
membrane and upon hitting its end releases neurotransmitters in nerve terminals.
The neurotransmiters diffuse across synapse and bind to receptors on the surface
of target cell's dendrite, which causes response in target.\cite{brainFacts}

%\subsection{Measurement technology} - CT, EEG, optical.. maybe?

\section{Electroencephalography}
The nature of human nervous system, as has been presented, is electrical. It has
been observed that the variation of surface electrical potential measured on the
scalp is related to amount of activity in underlying brain structures. EEG is a
method for measuring these potential variation using an array of electrodes
placed on measured subject's scalp and recording them for later processing.
\cite{eegClass}

The main advantage of EEG over other methods is speed as it can record respond
to stimulus within fractions of a second. \cite{eegFund} Applications of EEG
include:
\begin{itemize}
  \item Research -- monitoring during cognitive and motoric tasks
  \item Medical -- diagnosis of brain diseases
  \item Human computer interaction -- performing commands using brain activity  
\end{itemize}
Recently, the EEG based devices also penetrated consumer market and users can
monitor brain activity at home, play simple games and control toys using
their thoughts. (footnote-quadcopter)

\subsection{Basic principles}
It is impossible to measure or distinguish electrical activity of each neuron
with EEG, because these are asynchronous and cancel each other out. 
What EEG measures is summated potential of neuronal activity, which includes
spontaneus electrical activity of the cerebral network and cortical responses to
external and internal events. The responses to events, characterized by their
onset latency and voltage amplitude, are reffered to as \emph{event-related
potentials} and are either result of physical stimuli, or behavioral responses.
\cite{bcComm} %TODO: The activity results in relatively long-duration
% synchronous signals that appear as sinusoidal waves, hence the name brain waves.


\subsection{Measurement equipment}
The setup used for encephalographic measurements usually consist of: 
\begin{itemize}
  \item Electrodes with conductive media
  \item Amplifiers with filters
  \item A/D converter
  \item Recording device
\end{itemize}
% Electrodes
The electrodes exists in various forms but in this work we will focus on
headsets and electrode caps as these are non-invasive and require the least
expertise. These caps usually consists of small discs serving as electrodes made
of very conductive material, such as gold, silver or stainless steel. Commonly
used electrodes are made of Ag-AgCl disks with diameter of \SIrange[range-units
= single]{1}{3}{\mm} and have long leads that can be plugged into an
amplifier. \cite{eegFund} The discs can be in direct contact with scalp and
measure electric potential produced by brain, but conductive media in form of a
gel or paste is often used to increase conductivity even more by lowering
contact impedance, and improve readings at the lowest level. It also helps
electrodes to stick to surface so accidental shift from position is less likely.

% Cap
The electrodes are pre-mounted on a silicon cap in locations according to
standardized placement system, which will be discussed later in this section.
This both speeds up the setup stage and allows for unified mapping of electrodes
to head surface, but fails to account for different shape and features of each
individual's head. \cite{eegFund} This problem is usually solved by involving a
method for finding 3D coordinates of electrodes on the head. Such methods
include using magnetic field digitizer or elaborate algorithms that can
calculate position of each electrode from few distance and angle measurements by
utilizing specific properties of standard placement system. \cite{rapidPos}

% Amplifiers
The strength of signal measured by electrodes is in order of microvolts and
normally range from \SIrange{10}{500}{\uV}. \cite{neuralAmp} An amplifier is,
therefore, needed to bring the amplitude to higher levels so it can be processed
by other electrical circuits and components. The requirements on amplifiers for
use with EEG are high as they have to provide amplification only for physiological
signal, which should not be distorted in any way, reject superimposed noise and
interference signals, and protect both the equipment and measured subject from
current surges. Amplifiers conforming to these requirements are known as
\emph{biopotential amplifiers}. \cite{biopotAmp}
% Filters
A bandpass filter is then used to limit frequencies into a certain range of
interest. In some cases it may be already a part of an amplifier.
Another common filter is notch filter which is used to filter out noise
at frequency of power line. Depending on country, it may be set to
\SIlist[list-units = single, list-pair-separator = { or }]{50;60}{\Hz}.
\cite{deltaCompNREM} Such filter is only used if it is desirable to keep also
high frequencies as the interesting frequency bands usually lies bellow this
threshold.
% Trend in amplifier miniaturization
The trend in development of neural recording devices is heading in direction of
fully implanted systems(konzultovat). Consequently, energy efficient amplifiers
are being designed lately that are very small in size, may run on battery for
long periods of time and dissipate only little heat so they don't damage
surrounding tissue. \cite{neuralAmp}

% A/D converter
An A/D converter unit is then used to convert analog values to digital
representation. The converter should have resolution of at least 12 bits and
ideally 16 bits or more. With high number of electrodes, analog multiplexers are
sometimes used to lower the number of necessary converter units at the expense
of limited update frequency. The sampling frequency should be at least double of
the highest recorded frequency, for example the upper frequency limit set for
bandpass filter. This is known as Nyquist-Shannon sampling theorem and is
fundamental for correct signal reconstruction without aliasing artifact. The
preferred sampling frequency is \SIrange{256}{400}{\Hz}. \cite{guidDigEEG}

% Recording device
Converted samples from A/D converters are then stored in memory for further
processing which will be discussed in another part of this section
\ref{sub:dataAnalysis}. A recording device may be represented by a computer or a
different piece of specialized equipment. The computer can be additionally
equipped with digital signal processor unit so that CPU load is lower and can be
used for other tasks.

\subsection{Electrode placement systems}
% Uvod
The need for standardized electrode placement was evident as early as 1947 when
the first International EEG congress held place in London. Various methods of
standardization were proposed and this effort finally resulted in the definition
of 10-20 electrode system in 1958 by H.H. Jasper. \cite{placeSys} 
% Popis 10-20
This system consists of 21 electrodes placed evenly between certain landmarks
and the labels of electrodes are derived from cerebrum lobes above which they
are located. The first contour can be found by connecting inion and nassion.
Inion is small pretuberance at the back of the head and nassion is located just
above bridge of the nose. The length of this line is measured and electrodes are
placed along it using following procedure. First electrode -- Fpz, is placed at
10\% of length from nassion. The electrodes Fz, Cz and Pz are placed in this
order from front to back with spacing of 20\% of length. Fz and Fpz are also
spaced by 20\%. Last electrode -- Oz, is placed at 10\% of length from inion
which equals 90\% of length from nassion. It should be clear now why the system
is called 10-20. The rest of electrodes are placed in similar fashion and this
can be seen at image.. %obrazok do prilohy

% Popis 10-10
The 10-20 system offers only limited resolution but it was sufficient at the
time of its creation because the main limiting factor was technology. However,
with technological advances in computers and signal processing, using more than
21 channels became feasible and, naturally, many sought to take advantage of
higher resolution. With more electrodes than what is 10-20 model capable of
accommodating, first extension to standard placement system was needed. The
extension, named 10-10 system, was proposed in 1985 and extended the number of
electrodes to 74. It uses additional coronal contours lying halfway between
original contours and combines the labels of these original contours to create
new label. For example, the contour lying between original contours F and C will
be labelled FC. \cite{placeSys} The position of electrodes according to this
system are shown..
% obrazok do prilohy

% Popis 10-5
The 10-5 electrode placement systems further extends the 10-10 system to allow
even higher number of channels to be used as systems with over 128 channels are
not uncommon any more and have become commercially available. The idea in
placement of new electrodes is similar to how 10-10 system extends from 10-20,
creating coronal contours halfway between the original ones. The nomenclature
uses naming in similar fashion as geographical directions. For example,
direction between North and North-West is labelled as North-North-West and so
contour between C-contour and CP-contour will be labelled CCP-contour.
This doubles the number of contours and also the number of electrodes in contour
is doubled, increasing the number of electrodes by approximately 4 times.
The total number of possible locations is around 345 and may vary depending on
how many electrodes are included for the most inferior rows. \cite{placeSys}
This system is in proposition stage and is yet to be recognized as standard, but
it is currently only work in this area, therefore can be considered as relevant
and some equipment already adheres to it.

\subsection{Measurement procedure}
Before measurement the electrodes are cleaned thoroughly to remove any
impurities that could have an impact on it. The skin is also cleaned from oils
and brushed from dried parts. It is important to adhere to strict hygiene as
this might cause irritation and inflammation, and with repeated measurements may
develop into an infection.\cite{eegFund} The subject is then seated comfortably
to eliminate any unnecessary movement, because it could spoil the measured data.
(cite?) Electrodes or cap are placed on subject's scalp and recording can begin.
In case of a research oriented session, the subject is usually instructed to
perform specific tasks such as imagining moving certain part of body, rotating
an object in 3D or focusing on specific part of display. \cite{bcComm} For other
purposes, such as medical diagnosis, subjects may be monitored while laying on
their back with closed eyes or during sleep.

\subsection{Data analysis} \label{sub:dataAnalysis}
The recorded data are subject to further processing using numerical filters and
transforms to improve signal-to-noise ratio and extract desired features. 
% Clasification by frequency band
One such feature is brain activity at certain frequency. The frequency of brain
waves range from \SIrange{1}{150}{\Hz}. This range can be further divided
into six common categories\cite{dominantF}:
\begin{itemize}
  \item Delta waves -- below 4 Hz
  \item Theta waves -- between 4 and 8 Hz
  \item Alpha / Mu waves -- between 8 and 13 Hz
  \item Beta waves -- between 13 and 30 Hz
  \item Gamma waves -- between 30 and 80 Hz
  \item High gamma waves -- above 80 Hz
\end{itemize}
A healthy person exhibits brain waves mostly in the first four categories. Each
band is related to certain group of activity in brain and can be used for
diagnosis as abnormal resting powers in certain bands were linked to various
mental and physiological diseases. \cite{dominantF} Delta waves are normally
distributed over scalp and may be significant during deep sleep, in childhood or
in serious organic brain disease. \cite{eegClass} Theta waves are related to
cognitive tasks such as working memory and error monitoring tests. Alpha power
is increased during inattention and lack of visual input, therefore related to
perception. Mu power, on the other hand, is linked to movement and is decreased
when person performs a motor action. The distinction between alpha and mu waves
is made by considering the location of electrode. While alpha waves form at the
back of the scalp, mu waves can be observed in a strip of brain from ear to ear
called motor cortex. Finally beta waves are low amplitude, high frequency waves
that have power reduced at the onset of movement, rebound if the movement is
sustained and are enhanced if the movement is suppressed. \cite{dominantF}

% Classifier reference
Many researchers proposed implementation of classifiers capable of identifying
these frequencies in signal using various approaches. One such method that is
used in this work is described in detail in section \ref{eegClassifier}.

% Classification by pattern
Another set of features are patterns that represent certain activity more
clearly than classification by frequency. For example, the imagined movement of
finger can be distinguished from imagined movement of leg with this method. The
classification accuracy is, however, highly individual and the classification
system usually needs tuning or calibration process for each user. \cite{bcComm}
Common approach to this problem is training a neural network that can classify
patterns in brain waves with accuracy high enough for normal usage.

\chapter{Approaches to signal processing and visualization} \label{appProcVis}
\section{Signal processing} \label{sec:sigProc}
As presented in section \ref{sub:dataAnalysis}, processing is important
step to ease analysis of recorded data by filtering out noise and selecting
features. This section will, therefore, provide general information about
methods of signal processing and section \ref{signalExtraction} will put them
specifically into context of EEG signal processing.

%\subsection{Nyquist-Shannon theorem} maybe

\subsection{Low, high and band pass filters}

\subsection{Discrete Fourier transform}

\subsection{Discrete wavelet transform}
transform is defined as decomposition of mother wavelet $\psi(t)$ into child
wavelets by choosing subsets of scales (a) and positions (b). 

The decomposition may be repeated..

The daubechies wavelets..


\section{Data visualization methods}
So far, only methods of measuring and processing data from EEG have been
discussed, but the primary goal is to visualize them. Therefore, this section
will discuss various methods of data visualization using computers and common
display devices such as monitors and screens, and how these visualizations can
be used to help humans analyze data more easily.

\subsection{2D representations}
Display devices and other media used for presenting information have mostly
two-dimensional nature. This has great implications for how the data are usually
visualized and manipulated. The most natural representations are those that are
already organized spatially as two-dimensional, without needing any projections
and mappings. It is still possible to add the next dimensions through usage of
colors, different shapes and sizes, but the diagram was from start intended to
take on two-dimensional form. The most commonly used diagrams are based on
graphs and charts, although schematics and maps are also popular.

The graph is type of a diagram made of interconnected objects. The connection
may be represented by a line or curve which may be directed, meaning that it
goes only one way. Graphs are usually used for visual representations of data
where individual entities and their relations can be recognized, for example a
network of roads between cities, but they are also usefull for displaying
hierarchies.

The chart is a visual representation of data useful for plotting, categorizing
and showing trends. It may come in many forms, like bars or lines drawn in an
area designated by axes with scales, or slices of a pie. Choosing the most
suitable one, so that the most significant fact stands out, is important step in
data visualization.

\subsection{3D models}
The world and objects within it are perceived by humans as three-dimensional
and, therefore, it is preferable to use three-dimensional representations of
objects called 3D models. However, there is lack of technology for displaying
such representations truly three-dimensionally, with holograms being the most
advanced one. Because of that, the models must be projected into two dimensions
so that they can be displayed using existing devices. This is done using
projection matrices during process called rendering. The two most common
projections are orthogonal and perspective.

There are multiple ways to create the 3D model. It is possible to scan real
world objects by various means, such as tomography and optical surface imaging,
or use special modelling software and reconstruct the model from basic
primitives. The model may have defined volume using volumetric or voxel
representations or it can be just a surface of an object which is usually
represented by mesh. A mesh is collection of points in 3D space called vertices
which are connected to form basic primitives, like triangles and polygons.

\section{Programmable graphics pipeline}
A graphics pipeline represents the process of rendering and its stages. The
input data in form of vertices, colors and other information are input to the
first stage which processes and passes them down the pipeline to another stage.
The result of final stage is rendered image of scene. Before programmable
pipeline was developed, programmers could only use vendor defined operations and
combine them to create their application which imposed certain constraints on
what could be done. This was called a fixed pipeline, because the action
performed by each stage was fixed and could be only modified through parameters
or states. With introduction of programmable pipeline, it was possible for
programmers to step into rendering process in several places and define their
own techniques. The custom programs that have become part of pipeline are called
shaders. In following text we will present the three most important types of
shaders with respect to their position in pipeline. The terminology used here is
according to OpenGL, but basic principles are similar for most of the graphics
card APIs.
%TODO obrazok pipeliny

\subsection{Vertex shader}
A vertex shader is at the very front of graphics pipeline, just after primitive
processing. It allows to modify properties of vertices before they enter
geometry shader or primitive assembly stage. The input to vertex shader is
single vertex with all related information. Typical usage of this stage consists
of applying projection and transformation matrices, gouraud shading,
displacements and controlling particle effects.

\subsection{Geometry shader}
A geometry shader, if present, is executed right after vertex shader but instead
of working with isolated vertices, it works with whole primitives like points,
lines and triangles. It may perform transformation from one type of primitive to
another and also emit completely new geometry. For example, it is possible to
have as input only one point and output may be circle with that point as a
center made of varying number of triangles, depending on how far from camera
the point was. This not only saves time-expensive transport operation between
CPU and GPU, but also optimizes performance by dynamically lowering details.

\subsection{Fragment shader}
A fragment shader works with individual pixels, produced by rasterizer after the
primitives have been assembled. However, the three-dimensional information have
not been discarded yet and is accessible during processing. This allows to apply
three-dimensional effects on the finest level, such as phong shading. The output
of this program is single color that will be displayed on that specific pixel.

\chapter{EEG specific procedures and solutions} \label{eegProcAndSol}
\section{Extraction of features from EEG signal} \label{signalExtraction}
\subsection{Frequency band classifier} \label{eegClassifier}
In this work we will use classifier using discrete wavelet transform and Fourier
transform as proposed by M.M. Shaker. \cite{eegWaveFt} The process of
classification consists of three phases. First, the data from EEG are
normalized, which means using band pass filter with desired frequency range,
usually \SIrange{1}{30}{\Hz}. This signal is then passed to DWT for
decomposition into multiple levels of detail and approximation coefficients
using Daubechies wavelets. The suggested number of levels is four. Each level is
then processed by DFT and the result gives and indication to the frequencies
contained in the band.
%TODO: more detail

\section{Overview of existing solutions}
\label{existSol}
We are aware that our work is not first in this field and there is much to be
learned from previous attempts. This section will analyze existing solutions
by focusing on their user interface, features, extensibility, intuitiveness 
and overall usability.

\subsection{Emotiv}
Emotiv is a company specializing in area of EEG devices for consumer market.
Currently they offer two options -- 14 channel EPOC and 5 channel Insight
headsets. These headsets come with built-in amplifiers, filters and A/D
converters, and communicate wirelessly with computer through bluetooth. As
we lack necessary hardware, we will review this solution from videos posted on
the internet by users who own the headset and from information available on
company's website.

The headset is accompanied with software, which has to be bought through store
separately. On one side, the store allows the developers to create new
applications independently but as a result, there is lack of single, unified
user experience. This is caused not only by different styles the authors of each
application used, but also because each application have its own set of
settings, controls and displays, many of which are duplicated between
applications. For example, a chart with signals from electrodes is included in
both TestBench and 3D brain activity map applications. There is also another
brain activity map that displays each frequency band in 2D and the settings,
such as gain factor and buffer size are not shared in any way between
applications, resulting in different behavior, which can be quite confusing.
However, the focus on ordinary computer users can be felt as the applications,
when considered as standalone products, are visually nice, polished and
user-friendly.

Featurewise, the applications are ranging from visualization software and data
importers to games. One important feature that seems to be missing from most of
the applications is lack of any control of time, meaning they are only able to
display actual values. This is very limiting factor for data analysis, as one of
basic tasks performed is comparing data. Being able to do so between two or more
moments in time is definitely desirable. The SDK for creating new applications
is freely available, so anyone can start developing.

\subsection{Svarog}
Svarog stands for Signal Viewer, Analyzer and Recorded on GPL and is
implemented in Java. It is intended for use as an advanced analysis tool capable
of both online and offline signal viewing and processing. The data may be in any
data format as long as SignalML description is provided.

The application offers only basic visualization methods. Main GUI element
visible after starting the program is chart with EEG wavelets. It allows to
modify amount of space between signals, the amplitude and time scale, select
part of a signal on one or multiple electrodes, zoom in or out and an
interesting tool is FFT viewer that can show FFT for segment of signal in
superimposed window. Another interesting element is time-frequency map that is
used for showing results of matching pursuit algorithm that is one of available
processing tools. Time is on horizontal axis, frequency on vertical axis and
amplitude is represented by color in range from blue to red. However, there is
no brain map and other visually more appealing elements.

The GUI is sometimes cluttered with too many options, which could have been
hidden in some advanced view, but overall is clean, quite customizable and
informs user about progress of operations. It also allows to create auxiliary
signal plots, which are useful for signal comparison. With too many signals
the responsiveness degrades, probably because the plots are rendered in software.
\chapter{Concept and design} \label{concept}
Theoretical concept for practical part.

Important question to ask is who will be the targeted audience. The difference
between targeting ordinary users and researchers could be seen in section
\ref{existSol}. The original assignment predetermines this work to be used
primarily for academic purposes. Nevertheless, we will also incorporate the
ideas of visually appealing graphical elements and friendly user interface as
they can dramatically change the experience, which should be important even when
the targeted group is small and proficient in a given area as it may speed up
learning process and help focus on the analysis, rather than the application
itself.
\section{User interface}
\emph{2 pages}
Drawings, mockups, layouts, command prompt parameters.

It should be easy to experiment with different values and explore new options.
The visualization settings should be accessible, not hidden behind several
levels of menus and dialogs.
\section{Code structure}
\emph{3 pages}
\subsection{Logical division}
The division on subsystems for graphics context setup, signal processing, gpu
rendering procedures, user interface and model importer.
\subsection{Classes and communication}
Structure of code defined by C++ classes, probably should be just global
overview with references to doxygen documentation, maybe some graphical code
maps.
\chapter{Implementation}
\label{implementation}
\emph{? pages}
Will cover implementation details, algorithms, significant mechanisms, shader
programming.. The logical division defined earlier will be probably used to
describe each part separately.
\section{Tools and libraries}
\emph{0.5-1 page}
Short enumeration, links or references to websites.
\section{Input data processor}
\subsection{Input format}
\subsection{Filters}
\section{Model importer}
\section{3D rendering system}
\section{Plugin system}
\section{Graphical user interface}
\section{\ldots}
\chapter{Results}
Summarization of results obtained by this work, final graphs and tables,
higlighting of the most interesting parts, presentation of user 
research -- opinions, suggestions,
feture requests..
\chapter{Discussion}
Discussing the results in regard to referenced literature and their results.
Showing significance of findings, questioning them, providing several
perspectives and means for argumentation.
\chapter{Conclusions}
Refering to introduction and checking with goals, if everything required was
done, what couldn't be done and why. Placing the work into wider context of
relevant areas of research -- medicine, bioinformatics, user interfaces..
Part about possible plans for future, improvment, enhancements, folow
up..
%=========================================================================
